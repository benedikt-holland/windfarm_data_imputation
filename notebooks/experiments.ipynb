{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "763d421a",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5067f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils.prep_data import load_data, split_data, mask_data, Experiment\n",
    "from utils.train import train\n",
    "from utils.dataset import WindFarmDataset\n",
    "from GCGRU.GRU import GRU\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8f3e63",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3b3cce",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "088b47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(columns=[\"TurbID\", \"P_norm\", \"datetime\"])\n",
    "nan_mask = ~data[\"P_norm\"].isna().to_numpy()\n",
    "# Assign mean to nan values\n",
    "data_mean = data[\"P_norm\"].mean()\n",
    "data.loc[~nan_mask, \"P_norm\"] = data_mean\n",
    "# subset of turbines for faster experiments\n",
    "turbines = [9, 10, 11, 12, 31, 32, 33, 34, 35, 52, 53, 54, 55, 56, 57]\n",
    "data = data[data[\"TurbID\"].isin(turbines)]\n",
    "train_data, val_data, test_data = split_data(data, splits=[0.7, 0.2, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0b63a",
   "metadata": {},
   "source": [
    "Reset data split indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe4ed998",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(drop=True, inplace=True)\n",
    "val_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb21c7f",
   "metadata": {},
   "source": [
    "#### Create masks for different splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c52a3320",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_percentages = [0.01, 0.02, 0.05, 0.1]\n",
    "blackout_periods = [30, 60, 150, 300]\n",
    "maintenance_periods = [1, 2, 7, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72b010f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks_random = { size: mask_data(train_data, base_mask=None, experiment=Experiment.RANDOM, size = size) for size in random_percentages }\n",
    "val_masks_random = { size: mask_data(val_data, base_mask=None, experiment=Experiment.RANDOM, size = size) for size in random_percentages }\n",
    "test_masks_random = { size: mask_data(test_data, base_mask=None, experiment=Experiment.RANDOM, size = size) for size in random_percentages }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae258423",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks_blackout = { size: mask_data(train_data, base_mask=None, experiment=Experiment.BLACKOUT, size=size) for size in blackout_periods }\n",
    "val_masks_blackout = { size: mask_data(val_data, base_mask=None, experiment=Experiment.BLACKOUT, size=size) for size in blackout_periods }\n",
    "test_masks_blackout = { size: mask_data(test_data, base_mask=None, experiment=Experiment.BLACKOUT, size=size) for size in blackout_periods }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3128b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks_maintenance = { size: mask_data(train_data, base_mask=None, experiment=Experiment.MAINTENANCE, size=size) for size in maintenance_periods }\n",
    "val_masks_maintenance = { size: mask_data(val_data, base_mask=None, experiment=Experiment.MAINTENANCE, size=size) for size in maintenance_periods }\n",
    "test_masks_maintenance = { size: mask_data(test_data, base_mask=None, experiment=Experiment.MAINTENANCE, size=size) for size in maintenance_periods }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978bfbd1",
   "metadata": {},
   "source": [
    "### RNN-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22e304c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sliding_window(data: np.ndarray, data_mask: np.ndarray, nan_mask: np.ndarray, t: int = 6 * 24):\n",
    "    X_window, y_window = [], []\n",
    "    for i in range(data.shape[0] - t - 1):\n",
    "        xw = data[i:(i+t)]\n",
    "        # Simulate missing data on X\n",
    "        xw[~data_mask[i:(i+t)]] = data_mean\n",
    "        X_window.append(xw)\n",
    "        # Keep unmasked true data in y\n",
    "        y_window.append(np.stack([data[(i+1):(i+1+t)], data_mask[(i+1):(i+1+t)], nan_mask[(i+1):(i+1+t)]], axis=-1))\n",
    "\n",
    "    # conversion to np.ndarray -> then torch.Tensor because of python list of np.ndarray\n",
    "    return torch.tensor(np.array(X_window)).unsqueeze(-1).to(device), torch.tensor(np.array(y_window)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71398445",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_9 = train_data[train_data[\"TurbID\"] == 9][\"P_norm\"].to_numpy()\n",
    "mask_9 = train_masks_random[0.05][train_data[train_data[\"TurbID\"] == 9].index]\n",
    "nan_mask_9 = nan_mask[train_data[train_data[\"TurbID\"] == 9].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69898aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_9[~nan_mask_9] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2665f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24366, 144, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y = format_sliding_window(data_9, mask_9, nan_mask_9)\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9704fb4e",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "250ace75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GRU for turbine 9\n",
      "Epoch: 1;\ttraining loss: 0.0028;\tvalidation loss: 0.0011\n",
      "Epoch: 10;\ttraining loss: 0.0006;\tvalidation loss: 0.0008\n",
      "Epoch: 20;\ttraining loss: 0.0006;\tvalidation loss: 0.0008\n",
      "Stopping early on epoch 26\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 10\n",
      "Epoch: 1;\ttraining loss: 0.0321;\tvalidation loss: 0.0023\n",
      "Epoch: 10;\ttraining loss: 0.0006;\tvalidation loss: 0.0007\n",
      "Epoch: 20;\ttraining loss: 0.0006;\tvalidation loss: 0.0007\n",
      "Epoch: 30;\ttraining loss: 0.0006;\tvalidation loss: 0.0007\n",
      "Epoch: 40;\ttraining loss: 0.0006;\tvalidation loss: 0.0007\n",
      "Epoch: 50;\ttraining loss: 0.0006;\tvalidation loss: 0.0007\n",
      "Epoch: 60;\ttraining loss: 0.0006;\tvalidation loss: 0.0007\n",
      "Epoch: 70;\ttraining loss: 0.0006;\tvalidation loss: 0.0007\n",
      "Epoch: 80;\ttraining loss: 0.0006;\tvalidation loss: 0.0007\n",
      "Epoch: 90;\ttraining loss: 0.0006;\tvalidation loss: 0.0007\n",
      "Stopping early on epoch 96\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 11\n",
      "Epoch: 1;\ttraining loss: 0.0127;\tvalidation loss: 0.0011\n",
      "Epoch: 10;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Epoch: 20;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Epoch: 30;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Epoch: 40;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Epoch: 50;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Epoch: 60;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Epoch: 70;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Stopping early on epoch 79\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 12\n",
      "Epoch: 1;\ttraining loss: 0.0493;\tvalidation loss: 0.0012\n",
      "Epoch: 10;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Epoch: 20;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Epoch: 30;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Epoch: 40;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Epoch: 50;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Epoch: 60;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Epoch: 70;\ttraining loss: 0.0007;\tvalidation loss: 0.0007\n",
      "Stopping early on epoch 72\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 31\n",
      "Epoch: 1;\ttraining loss: 0.0026;\tvalidation loss: 0.0008\n",
      "Epoch: 10;\ttraining loss: 0.0005;\tvalidation loss: 0.0006\n",
      "Epoch: 20;\ttraining loss: 0.0005;\tvalidation loss: 0.0006\n",
      "Epoch: 30;\ttraining loss: 0.0005;\tvalidation loss: 0.0006\n",
      "Epoch: 40;\ttraining loss: 0.0006;\tvalidation loss: 0.0006\n",
      "Stopping early on epoch 40\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 32\n",
      "Epoch: 1;\ttraining loss: 0.0021;\tvalidation loss: 0.0007\n",
      "Epoch: 10;\ttraining loss: 0.0005;\tvalidation loss: 0.0006\n",
      "Epoch: 20;\ttraining loss: 0.0005;\tvalidation loss: 0.0006\n",
      "Stopping early on epoch 26\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 33\n",
      "Epoch: 1;\ttraining loss: 0.0064;\tvalidation loss: 0.0008\n",
      "Epoch: 10;\ttraining loss: 0.0005;\tvalidation loss: 0.0006\n",
      "Epoch: 20;\ttraining loss: 0.0005;\tvalidation loss: 0.0006\n",
      "Stopping early on epoch 26\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 34\n",
      "Epoch: 1;\ttraining loss: 0.0072;\tvalidation loss: 0.0007\n",
      "Epoch: 10;\ttraining loss: 0.0005;\tvalidation loss: 0.0006\n",
      "Epoch: 20;\ttraining loss: 0.0005;\tvalidation loss: 0.0006\n",
      "Epoch: 30;\ttraining loss: 0.0005;\tvalidation loss: 0.0006\n",
      "Stopping early on epoch 31\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 35\n",
      "Epoch: 1;\ttraining loss: 0.0216;\tvalidation loss: 0.0011\n",
      "Epoch: 10;\ttraining loss: 0.0006;\tvalidation loss: 0.0006\n",
      "Epoch: 20;\ttraining loss: 0.0006;\tvalidation loss: 0.0006\n",
      "Epoch: 30;\ttraining loss: 0.0006;\tvalidation loss: 0.0005\n",
      "Epoch: 40;\ttraining loss: 0.0006;\tvalidation loss: 0.0005\n",
      "Epoch: 50;\ttraining loss: 0.0006;\tvalidation loss: 0.0005\n",
      "Stopping early on epoch 57\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 52\n",
      "Epoch: 1;\ttraining loss: 0.0607;\tvalidation loss: 0.0021\n",
      "Epoch: 10;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 20;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 30;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 40;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 50;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 60;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Stopping early on epoch 62\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 53\n",
      "Epoch: 1;\ttraining loss: 0.0248;\tvalidation loss: 0.0013\n",
      "Epoch: 10;\ttraining loss: 0.0004;\tvalidation loss: 0.0004\n",
      "Epoch: 20;\ttraining loss: 0.0004;\tvalidation loss: 0.0004\n",
      "Epoch: 30;\ttraining loss: 0.0004;\tvalidation loss: 0.0004\n",
      "Epoch: 40;\ttraining loss: 0.0004;\tvalidation loss: 0.0004\n",
      "Epoch: 50;\ttraining loss: 0.0004;\tvalidation loss: 0.0004\n",
      "Epoch: 60;\ttraining loss: 0.0004;\tvalidation loss: 0.0004\n",
      "Stopping early on epoch 65\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 54\n",
      "Epoch: 1;\ttraining loss: 0.0183;\tvalidation loss: 0.0014\n",
      "Epoch: 10;\ttraining loss: 0.0005;\tvalidation loss: 0.0007\n",
      "Epoch: 20;\ttraining loss: 0.0005;\tvalidation loss: 0.0007\n",
      "Epoch: 30;\ttraining loss: 0.0005;\tvalidation loss: 0.0007\n",
      "Epoch: 40;\ttraining loss: 0.0005;\tvalidation loss: 0.0007\n",
      "Epoch: 50;\ttraining loss: 0.0005;\tvalidation loss: 0.0007\n",
      "Epoch: 60;\ttraining loss: 0.0005;\tvalidation loss: 0.0007\n",
      "Epoch: 70;\ttraining loss: 0.0005;\tvalidation loss: 0.0007\n",
      "Epoch: 80;\ttraining loss: 0.0005;\tvalidation loss: 0.0007\n",
      "Stopping early on epoch 80\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 55\n",
      "Epoch: 1;\ttraining loss: 0.0121;\tvalidation loss: 0.0010\n",
      "Epoch: 10;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 20;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 30;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 40;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 50;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 60;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 70;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 80;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 90;\ttraining loss: 0.0005;\tvalidation loss: 0.0004\n",
      "Epoch: 100;\ttraining loss: 0.0006;\tvalidation loss: 0.0005\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 56\n",
      "Epoch: 1;\ttraining loss: 0.0013;\tvalidation loss: 0.0006\n",
      "Epoch: 10;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 20;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Epoch: 30;\ttraining loss: 0.0005;\tvalidation loss: 0.0006\n",
      "Stopping early on epoch 31\n",
      "\n",
      "\n",
      "\n",
      "Training GRU for turbine 57\n",
      "Epoch: 1;\ttraining loss: 0.0065;\tvalidation loss: 0.0006\n",
      "Epoch: 10;\ttraining loss: 0.0005;\tvalidation loss: 0.0005\n",
      "Stopping early on epoch 19\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {turb_id: GRU(1, 16, 1) for turb_id in data['TurbID'].unique()}\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "turbine_train_losses, turbine_val_losses = {}, {}\n",
    "for turb_id, model in models.items():\n",
    "    optimizer = torch.optim.Adam(list(model.parameters()), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "\n",
    "    turb_train_data = train_data[train_data['TurbID'] == turb_id]['P_norm'].to_numpy()\n",
    "    turb_train_mask = train_masks_random[0.05][train_data[train_data[\"TurbID\"] == turb_id].index]\n",
    "    turb_train_nan_mask = nan_mask[train_data[train_data[\"TurbID\"] == turb_id].index]\n",
    "\n",
    "    X_train_window, y_train_window = format_sliding_window(turb_train_data, turb_train_mask, turb_train_nan_mask)\n",
    "    train_loader = DataLoader(WindFarmDataset(X_train_window, y_train_window), batch_size=batch_size)\n",
    "\n",
    "\n",
    "    turb_val_data = val_data[val_data['TurbID'] == turb_id]['P_norm'].to_numpy()\n",
    "    turb_val_mask = val_masks_random[0.05][val_data[val_data[\"TurbID\"] == turb_id].index]\n",
    "    turb_val_nan_mask = nan_mask[val_data[val_data[\"TurbID\"] == turb_id].index]\n",
    "\n",
    "    X_val_window, y_val_window = format_sliding_window(turb_val_data, turb_val_mask, turb_val_nan_mask)\n",
    "    val_loader = DataLoader(WindFarmDataset(X_val_window, y_val_window), batch_size=batch_size)\n",
    "\n",
    "\n",
    "    print(f\"Training GRU for turbine {turb_id}\")\n",
    "    models[turb_id], train_losses, val_losses = train(model, train_loader, val_loader, optimizer, criterion, epochs=epochs, patience=10)\n",
    "    print(\"\\n\\n\")\n",
    "    turbine_train_losses[turb_id] = train_losses\n",
    "    turbine_val_losses[turb_id] = val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dffe5233",
   "metadata": {},
   "outputs": [],
   "source": [
    "for turb_id, model in models.items():\n",
    "    torch.save(model.state_dict(), f\"../data/params/turbine_{turb_id}_params.pth\")\n",
    "    with open(\"../data/params/train_losses.csv\", \"a\") as f:\n",
    "        line = f\"{turb_id},\" + \",\".join(map(str, turbine_train_losses[turb_id])) + \"\\n\"\n",
    "        f.write(line)\n",
    "    with open(\"../data/params/val_losses.csv\", \"a\") as f:\n",
    "        line = f\"{turb_id},\" + \",\".join(map(str, turbine_val_losses[turb_id])) + \"\\n\"\n",
    "        f.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba55f447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
